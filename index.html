<!DOCTYPE html>
<html lang="en" class=" js no-touch csstransitions" style=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>Rc-W024</title>
        <link href="images/PLASSF.png" rel="shortcut icon" type="image/x-icon" />
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
        <meta name="google-site-verification" content="tXGinevmz43rJKRTfCj6v5f8zN91tcmg6fdrrYUn-gI" />
        <!--[if lt IE 9]>
            <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
        <link rel="stylesheet" href="css/bootstrap.css">
        <link rel="stylesheet" href="css/perfect-scrollbar-0.4.5.min.css">
        <link rel="stylesheet" href="css/font-awesome.min.css">
        <link rel="stylesheet" href="css/academicons.min.css">
        <link rel="stylesheet" href="css/style.css?v6">
        <script type="text/javascript" src="./js/jquery-1.10.2.js"></script>
        <script type="text/javascript" src="./js/TweenMax.min.js"></script>
        <script type="text/javascript" src="./js/modernizr.custom.63321.js"></script>
        <script type="text/javascript" src="./js/bootstrap.min.js"></script>
        <script type="text/javascript" src="js/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>
        <script type="text/javascript" src="./js/custom.js"></script>
	<script type="text/javascript" src="./js/all.js"></script>
	<script type="text/javascript" src="./js/all.min.js"></script>
        <!-- start Mixpanel --><script type="text/javascript">(function(e,a){if(!a.__SV){var b=window;try{var c,l,i,j=b.location,g=j.hash;c=function(a,b){return(l=a.match(RegExp(b+"=([^&]*)")))?l[1]:null};g&&c(g,"state")&&(i=JSON.parse(decodeURIComponent(c(g,"state"))),"mpeditor"===i.action&&(b.sessionStorage.setItem("_mpcehash",g),history.replaceState(i.desiredHash||"",e.title,j.pathname+j.search)))}catch(m){}var k,h;window.mixpanel=a;a._i=[];a.init=function(b,c,f){function e(b,a){var c=a.split(".");2==c.length&&(b=b[c[0]],a=c[1]);b[a]=function(){b.push([a].concat(Array.prototype.slice.call(arguments,
0)))}}var d=a;"undefined"!==typeof f?d=a[f]=[]:f="mixpanel";d.people=d.people||[];d.toString=function(b){var a="mixpanel";"mixpanel"!==f&&(a+="."+f);b||(a+=" (stub)");return a};d.people.toString=function(){return d.toString(1)+".people (stub)"};k="disable time_event track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config reset people.set people.set_once people.increment people.append people.union people.track_charge people.clear_charges people.delete_user".split(" ");
for(h=0;h<k.length;h++)e(d,k[h]);a._i.push([b,c,f])};a.__SV=1.2;b=e.createElement("script");b.type="text/javascript";b.async=!0;b.src="undefined"!==typeof MIXPANEL_CUSTOM_LIB_URL?MIXPANEL_CUSTOM_LIB_URL:"file:"===e.location.protocol&&"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js".match(/^\/\//)?"https://cdn.mxpnl.com/libs/mixpanel-2-latest.min.js":"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js";c=e.getElementsByTagName("script")[0];c.parentNode.insertBefore(b,c)}})(document,window.mixpanel||[]);
mixpanel.init("ebfda33a74d82c326f768bb95f1db5ab");</script><!-- end Mixpanel -->
    </head>
    <body>

        <div id="wrapper">
            <a class="mobilemenu"><i class="fa fa-bars"></i></a>

            <div id="sidebar">
                <div id="main-nav" class="ps-container">
                    <div id="nav-container">
                        <div id="profile" class="clearfix">
                            <div class="portrait hidden-xs"></div>
                            <div class="title">
				<h2>吴若晨</h2>
                                <h2>RUOCHEN WU</h2>
				<h3>CommSensLab-UPC</h3>
				<h3>Universitat Politècnica de Catalunya · BarcelonaTech</h3>
                            </div>
                            
                        </div>
                        <ul id="navigation">
                            <li class="currentmenu">
                              <a href="#biography">
                                  <div class="icon"><i class="fa fa-user-secret"></i></div>
                                <div class="text">About Me</div>
                              </a>
                            </li>  
                            <li>
                              <a href="#education">
                                <div class="icon"><i class="fa fa-university"></i></div>
                                <div class="text">Education</div>
                              </a>
                            </li>

                            <li>
                                <a href="#publications">
                                    <div class="icon"><i class="fa fa-book"></i></div>
                                    <div class="text">Publications</div>
                                </a>
                            </li>

                            <li>
                              <a href="#project">
                                <div class="icon"><i class="fa fa-code"></i></div>
                                <div class="text">Project Experience</div>
                              </a>
                            </li>				

                            <li>
                              <a href="#awards">
                                <div class="icon"><i class="fa fa-trophy"></i></div>
                                <div class="text">Certificates & Awards</div>
                              </a>
                            </li>				
				
                            <li>
                              <a href="#contact">
                                  <div class="icon"><i class="fa fa-address-card"></i></div>
                                  <div class="text">Contact</div>
                              </a>
                            </li>
                        </ul>
                    </div>        
                </div>
                    <div class="social-icons">
                        <ul>
			    <li><a href="https://futur.upc.edu/RuochenWu?locale=en" target="_blank" title="UPC Personal Page"><i class="fa fa-id-badge"></i></a></li>
                            <li><a href="https://github.com/Rc-W024" target="_blank" title="GitHub"><i class="fab fa-github"></i></a></li>
		            <li><a href="https://twitter.com/RC001W" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a></li>
                        </ul>
                    </div>
            </div>

            <div id="main">
            
                <div class="page home" data-pos="home">
                    <div id="biography"  class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                
                                <div class="row">
                                    <div class="col-sm-2 visible-sm"></div>
                                    <div class="col-sm-8 col-md-5">
                                        <div class="biothumb">
                                            <img title="Ruochen Wu, Signal Theory and Communications Ph.D. candidate" src="images/wu404_foto.jpg" class="img-responsive">
                                            <div class="overlay">
                                                
                                                <h1 class="">Anonymous</h1>
                                                <ul class="list-unstyled">
                                                    <li>Action Code: <b>404</b></li>
                                                </ul>
                                            </div> 
                                            
                                               
                                        </div>
                                        
                                    </div>
                                    <div class="clearfix visible-sm visible-xs"></div>
                                    <div  class="col-sm-12 col-md-7">
                                        <h3  class="title">Bio
                                         <i class="quote">"无形战线 无私奉献 无名英雄 无上光荣"</i></h3>

                                            <p>WU Ruochen, currently a Ph.D. candidate in Signal Theory and Communications at Universitat Politècnica de Catalunya (UPC), Barcelona, Spain, under the supervision of Prof. <a href="https://futur.upc.edu/JordiJoanMallorquiFranquet?locale=en" target="_blank">Jordi Joan Mallorqui Franquet</a> and Prof. <a href="https://futur.upc.edu/AntoniBroquetasIbars?locale=en" target="_blank">Antoni Broquetas Ibars</a>. He received his M.Sc. Degree in Geomatics Engineering and Geoinformation from Universitat Politècnica de València (UPV), València, Spain, in 2021 under the supervision of Prof. <a href="http://www.upv.es/ficha-personal/laruiz" target="_blank">Luis Ángel Ruiz Fernández</a>, and a Diploma in Photogrammetry and Remote Sensing Technology from Yellow River Conservancy Technical Institute (YRCTI), Kaifeng, China, in 2017 under the supervision of Lec. <a href="https://www.yrcti.edu.cn/chgcxy/xygk/ldbz.htm" target="_blank">Dan Zhang</a>. He is being supported by the China Scholarship Council (CSC) to pursue his Ph.D. degree at <a href="https://commsenslab.upc.edu" target="_blank">Centre Específic de Recerca en Comunicació i Detecció UPC (Group of Remote Sensing, Antennas, Microwaves and Superconductivity, CommSensLab)</a><sup>&#8224</sup>, Department of Signal Theory and Communications, UPC, Spain.</p>
                                            <p><b>Research Interests:</b> Signal and Information Processing, Situation Awareness and Information Fusion, Artificial Intelligence (AI), Radar Remote sensing, and Cybersecurity, including Sensor Detection and Data Processing, Anomaly Detection, Radar Imaging Reconnaissance, Sensing/Imaging Techniques based on Microwaves and THz, Intelligent Perception for Autonomous Unmanned Systems, Information Countermeasure, Signals Intelligence (SIGINT), and Cyberspace Attack & Defense Countermeasure and Related Signal Processing.</p>
                                            <p><b>Past Interests:</b> Synthetic Aperture Radar (SAR) Technology, Aerospace Remote Sensing Image Interpretation/Processing/Classification, Target Detection and Recognition, Geospatial Intelligence (GEOINT), and Scene Matching and Guidance.</p>
                                            <p><b>Professional Activities:</b> 
					       <div><b>14 March 2022  &mdash; </b>Cross-training Activity: Workshop on professional perspectives of PhD graduates - The Collaborative Workshop on the Architecture of Smart Cameras (WASC 2022). (<a target="_blank" href="pub/Certificado_WASC2022.pdf">Certificate</a>)</div>
					       <div><b>8 December 2021  &mdash; </b>Student Member of the Electronic Countermeasure Society of the Chinese Institute of Electronics (CIE). (<a target="_blank" href="pub/member_cie.png">Membership Card</a>)</div></p>
					    <p><b style="color: red;">Special Mention</b>
					    <div>&#8224 Excellence Research Unit Maria de Maeztu (MINECO Grant: <b>MDM-2016-600</b>).</div>
					    </p>
                                            <p><b>Hobbies: </b>Strolling, automotives, travel, GTA, LEGO, and listening to cross talk.</p>
                                    </div>
                                    
                                </div>
                            </div>        
                        </div>
                    </div>

                    <div class="pagecontents">
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="row">
                                    <div id="education" class="col-md-10 col-md-offset-1">
                                        <div class="title text-center">
                                            <h3>Education</h3>
					    <i class="quote"> </i>
                                        </div>
                                        <ul class="ul-card">
                                            <li>
                                                <div class="dy">
                                                    <span class="degree">Ph.D. candidate</span>
                                                    <span class="year">2021.11 - Now</span>
                                                </div>
                                                <div class="description">
						    <p>Signal Theory and Communications (Research line: Radar Remote Sensing and Situation Awareness)</p>
                                                    <p class="where">CommSensLab-UPC, Department of Signal Theory and Communications</p>
                                                    <p class="where">Universitat Politècnica de Catalunya (Polytechnic University of Catalonia), Spain</p>
						    <p class="where">Academic Evalution: <b>Satisfactory</b></p>
						    <p class="where">QS 2023 World Ranking: <b>343</b>; QS 2022 World Ranking by Subject: <b>52</b>.</p>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="dy">
                                                    <span class="degree">M.Sc.</span>
                                                    <span class="year">2018.09 - 2022.05</span>
                                                </div>
                                                <div class="description">
						    <p>Geomatics Engineering and Geoinformation (Research line: Remote Sensing Information Processing)</p>
                                                    <p class="where">School of Engineering in Geodesy, Cartography and Surveying</p>
                                                    <p class="where">Universitat Politècnica de València (Polytechnic University of Valencia), Spain</p>
						    <p class="where">GPA: <b>6,4/10,0</b></p>
						    <p class="where">QS 2023 World Ranking: <b>400</b>; QS 2022 World Ranking by Subject: <b>141</b>.</p>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="dy">
                                                    <span class="degree">Cert.</span><span class="year">2017.10 - 2018.06</span>
                                                </div>
                                                <div class="description">
                                                    <p>Language of Spanish (Castellano)</p>
                                                    <p class="where">Palencia International Junior College, Spain</p>
						    <p class="where">Level: <b>B2 Vantage</b> (Common European Framework of Reference for Languages)</p>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="dy">
                                                    <span class="degree">Dip.</span><span class="year">2014.09 - 2017.07</span>
                                                </div>
                                                <div class="description">
                                                    <p>Photogrammetry and Remote Sensing Technology (Study line: Satellite/UAV Image Processing)</p>
						    <p class="where">School of Surveying and Mapping Engineering</p>
                                                    <p class="where">Yellow River Conservancy Technical Institute, China</p>
						    <p class="where">World First-Class Higher Vocational College; High-Level Vocational Colleges with Chinese Characteristics (双高计划): Level <b>A</b>, Top <b>10</b></p>
						    <p class="where">GPA: <b>3,35/4,5</b></p>
                                                </div>
                                            </li>
                                        </ul>
                                    </div>
				</div>
			    </div>
			</div>

		        <div class="section color-2">
                            <div class="section-container">
                                <div class="row">
                                    <div id="publications" class="col-md-10 col-md-offset-1">
                                        <div class="title text-center">
                                            <h3>Publications</h3>
                                        </div>
                                        <ul type=disc>
					     <li> Two-Parameter CFAR Ship Detection Algorithm Based on Rayleigh Distribution in SAR Images <sup>*</sup>
				             <p> <b>Wu, R</b>. <i>Preprints 2021</i>, DOI: 10.20944/preprints202112.0280.v1</p>
					     <p> <a target="_blank" href="https://www.preprints.org/manuscript/202112.0280/v1">PDF</a>, <a href="https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Two-Parameter+CFAR+Ship+Detection+Algorithm+Based+on+Rayleigh+Distribution+in+SAR+Images&btnG=">BibTeX</a>, <a target="_blank" href="https://github.com/Rc-W024/SAR_Ship_detection_CFAR">GitHub</a></p>
					     <p> *<i> The research topic of this article is the same as that of the master thesis, which was published as a preprint in that the Master is a taught postgraduate program in which students are not advised to publish papers.</i></p>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>			    
			    
                        <div class="section color-2">
                            <div class="section-container">
                                <div class="row">
                                    <div id="publications" class="col-md-10 col-md-offset-1">
                                        <div class="title text-center">
                                            <h3>Thesis</h3>
                                            <i class="quote"> </i>
                                        </div>
                                        <ul class="ul-card">
					     <li>
                                                <div class="dy">
                                                    <span class="year">2021</span>
						    <span class="degree">Master Thesis (Trabajo Fin de Máster, TFM)</span>
                                                </div>
                                                <div class="description">
                                                    <p>DETECCIÓN Y RECONOCIMIENTO DE BLANCOS BASADOS EN IMÁGENES SAR (Target Detection and Recognition based on SAR Imagery)</p>
                                                    <p class="where">Universitat Politècnica de València</p>
						    <p class="where"><a target="_blank" href="http://hdl.handle.net/10251/166986">http://hdl.handle.net/10251/166986</a></p>
						    <p class="where">Grade: <b>8,0/10,0 (Notable)</b></p>
						    <p class="where"><a href="pub/TFM_Poster.pdf" target="_blank">Poster</a>, <a href="https://scholar.google.com/scholar?as_occt=title&as_q=Detecci%C3%B3n+y+reconocimiento+de+blancos+basados+en+im%C3%A1genes+SAR">BibTeX</a>, <a target="_blank" href="https://github.com/Rc-W024/SAR_Ship_detection_CFAR">GitHub</a></p>
                                                </div>
                                            </li>
					     <li>
                                                <div class="dy">
                                                    <span class="year">2017</span>
						    <span class="degree">Graduation Project</span>
                                                </div>
                                                <div class="description">
                                                    <p>基于街景影像的街道停车场判读项目 (Project of Street Parking Lot Interpretation based on Street View Images)</p>
						    <p class="where">Yellow River Conservancy Technical Institute</p>
						    <p class="where">Grade (Qualification): <b>Excellent</b></p>
                                                    <p class="where"><a href="pub/TFG_resume.pdf" target="_blank">Resume</a></p>
                                                </div>
                                            </li>
                                        </ul>
                                    </div>
                                </div>    
                            </div>                                
                        </div>			    			    
			    
                        <div class="section color-2">
                            <div class="section-container">
                                <div class="row">
                                    <div id="project" class="col-md-10 col-md-offset-1">
                                        <div class="title text-center">
                                            <h3>Project Experience</h3>
                                        </div>
                                        <ul class="timeline">
					   <li class="open">
                                                <div class="date">2022</div>
                                                <div class="circle"></div>
                                                <div class="data">
                                                    <div class="subject" style="padding-left: 0px;"><b>EU Project</b> - Advanced Active Safety Solutions for Micro-Mobility Vehicles</div>
                                                    <div class="text row">
                                                        <div class="col-md-11">
       EIT Urban Mobility, an initiative of the European Institute of Innovation and Technology (EIT), a body of the European Union, aims to accelerate solutions and the transition towards a user-centric, integrated and truly multimodal transport system.<br /><b>Responsibility:</b> Accelerometer data processing and signals analysis; development of anomaly event/accident detection algorithms; simulator verification.
                                                            <p><i>European Institute For Innovation And Technology (Grant: EIT-UM-2022-22265-RideSafeUM)</i></p>
							    <p><b>Scientific Coordinator:</b> Elisa Sayrol Clols, Josep Ramon Morros Rubió<br /><b>Researcher:</b> Josep Ramon Morros Rubió, Antoni Broquetas Ibars, <b>Ruochen Wu</b></p>
							    <p><a target="_blank" href="https://futur.upc.edu/33770719">RideSafeUM</a>; <a target="_blank" href="https://ridesafeum.com/">URL</a>, <a href="https://github.com/Rc-W024/Accident_Detection_Accel">GitHub</a></p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="date">2020</div>
                                                <div class="circle"></div>
                                                <div class="data">
                                                    <div class="subject" style="padding-left: 0px;"><b>TFM Project</b> - Ship Detection and Recognition based on Constant False Alarm Rate and Mathematical Morphological</div>
                                                    <div class="text row">
                                                        <div class="col-md-11">	
       Synthetic Aperture Radar (SAR) is an active type of microwave remote sensing. Using the microwave imaging system, remote sensing monitoring of the land and global ocean can be performed in any weather conditions around the clock. Target detection of the SAR image is one of the main needs of radar image interpretation applications. Therefore, it is of great practical importance and valuable to use satellite-provided radar image data to study target detection. In this project, the author applied a method combining CFAR and morphological operation for the task of ship detection and recognition of SAR images, and proposed an improved two-parameter CFAR algorithm based on Rayleigh distribution to solve the problem of ship echo signal position and image background noise interference. The probability density functions of sea clutter and a little amount of noise usually tend to be Rayleigh distribution, but there is still some clutter with obvious non-Rayleigh, which includes scale and shape parameters. 
							    <p><i>Universitat Politècnica de València</i></p> 
							    <p><b>Supervisor:</b> Luis Ángel Ruiz Fernández<br /><b>Author: Ruochen Wu</b></p>
                                                            <p>TFM 2020; <a target="_blank" href="http://hdl.handle.net/10251/166986">URL</a>, <a href="https://www.preprints.org/manuscript/202112.0280/v1">Preprints</a>, <a href="https://github.com/Rc-W024/SAR_Ship_detection_CFAR">GitHub</a></p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="date">2020</div>
                                                <div class="circle"></div>
                                                <div class="data">
                                                    <div class="subject" style="padding-left: 0px;"><b>Subject Project</b> - Comparative Exhibition Modeling of Bi-phase Target Area Changes based on Remote Sensing Images</div>
                                                    <div class="text row ">
                                                        <div class="col-md-11">
       Bi-phase orthophotos of the YRCTI in 2010 and 2020 have been modeled using photogrammetry technology, where the data in 2010 is the UAV images, and 2020, is the latest remote sensing images of Google Earth. The two models have made comparisons in Blender to complete the rendering. The project is mainly divided into three stages: data acquisition, photogrammetric data processing and modeling, 3D visualization construction, and final rendering.
                                                            <p><i>Geovisualisation and 3D Modelling, UPV</i></p>
                                                            <p><b>Tutor:</b> Luis Ángel Ruiz Fernández<br /><b>Author: Ruochen Wu</b></p></p>
                                                            <p>G3M 2020; <a target="_blank" href="pub/G3M_res.pdf">Results</a></p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </li>
					    <li>
                                                <div class="date">2019</div>
                                                <div class="circle"></div>
                                                <div class="data">
                                                    <div class="subject" style="padding-left: 0px;"><b>Local Project</b> - Reverse Modeling based on Photogrammetry Technology</div>
                                                    <div class="text row ">
                                                        <div class="col-md-11">
       This project aims to maintain and update the cultural heritage database of Valencia City Hall. We collected data on the bust sculpture in the Jardines de Monforte, and performed photogrammetry reverse modeling to generate a high-precision 3D model and a 3D printed model, which has been retained by Valencia City Hall.<br /><b>Responsibility:</b> Image orientation; coordinates calculation; establishment of linear relationship between image point coordinates and the corresponding object point spatial coordinates; 3D point cloud processing (including denoising and resampling); calculation of the topological relationship between points according to the neighborhood relationship of the spatial points; feature extraction; construction of the 3D model with feature constraints.
                                                            <p><i>UPV; Oficina Tècnica de Restauració i Manteniment de Monuments, Ajuntament de València (Exp. E-02001-2019-000699)</i></p>
                                                            <p><b>Tutor:</b> José Luis Lerma García<br /><b>Member: <b>Ruochen Wu</b>, Jimena Laura García Le Pera</p></p>
                                                            <p>G3M 2020; <a target="_blank" href="pub/X.pdf">Certificate</a>, <a target="_blank" href="pub/APS_Raw.JPG">Sculpture</a>, <a target="_blank" href="pub/20200209_203945.mp4">3D model</a>, <a target="_blank" href="pub/APS_model.jpg">3D printed model</a></p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
			    			    
			<div class="section color-2">
                            <div class="section-container">
                                <div class="row">
                                    <div id="awards" class="col-md-10 col-md-offset-1">
                                        <div class="title text-center">
                                            <h3>Special Mention</h3>
                                        </div>
                                        <ul type=disc>
					     <li> I was invited by Tsinghua AIR Webinar to deliver a talk "Towards Unconstrained Image/Video Deep Understanding" on 19th July 2022 (<a target="_blank" href="https://mp.weixin.qq.com/s/6LXelSYFByRt1VdayeGvRQ">Link</a>).
					     <li> I was invited by CSIG Webinar to deliver a talk "Towards Unconstrained Image/Video Deep Understanding" on 28th June 2022 (<a target="_blank" href="https://mp.weixin.qq.com/s/dcS3JCAItatpol4RuwGKlQ">Link</a>).
					     <li> Officially Interviewed by CSIG. (<a target="_blank" href="https://mp.weixin.qq.com/s/TVVMmBPGSuM41QPaBW4Okw">Link</a>)
					     <li> Officially Interviewed by Beijing Association for Science and Technology, due to a series of contributions on "Unconstrained Image/Video Deep Understanding" (<a target="_blank" href="https://mp.weixin.qq.com/s/C9VpNkyKWMv5v1KYKCRAig">BAST Official Interview1</a>, <a href="pub/interview22.pdf" target="_blank">BAST Official Interview2</a>, <a target="_blank" href="https://mp.weixin.qq.com/s/XyXkrOySH1oAZSQ4z5vMew">BAST Official Interview3</a>).
					     <li> Baidu PaddlePaddle officially merged <a target="_blank" href="https://github.com/ZhaoJ9014/face.evoLVe">face.evoLVe</a> to better facilitate more cutting-edge researches and applications on facial analytics and human-centric multi-media understanding (<a target="_blank" href="https://mp.weixin.qq.com/s/JT_4pqRvSsAOhQln0GSH_g">Official Announcement</a>).
					     <li> I have co-organized a VALSE Tutorial with Assoc. Prof. <a target="_blank" href="https://sites.google.com/site/xingxingwei1988/">Xingxing Wei</a> on the topic of "对抗环境下的深度合成和鉴别" on 08/09/2021 (<a target="_blank" href="https://mp.weixin.qq.com/s/Mfy639FcGKt6XYQU-iXJgA">Link</a>).
					     <li> I have co-organized a VALSE Webinar with Dr. <a target="_blank" href="https://sites.google.com/view/wenguanwang">Wenguan Wang</a> and Prof. <a target="_blank" href="https://wangzwhu.github.io/home/">Zheng Wang</a> on the topic of "Human-Centric Vision Techniques" on 13/01/2021 (<a target="_blank" href="https://mp.weixin.qq.com/s/cAovsOUUJtSFqqJHNOI5Ew">Link</a>).
					     <li> I was invited by Qihoo 360 to attend the <a href="pub/2020SH.jpg" target="_blank">"2020上海数字创新大会"</a> on 05/12/2020 as a panel guest of "人工智能给网络空间带来的机遇与挑战" session.
					     <li> I have co-organized a VALSE Webinar with Prof. <a target="_blank" href="http://changxu.xyz">Chang Xu</a> on the topic of "Visual Generation and Synthesis" on 23/09/2020 (<a target="_blank" href="http://valser.org/article-385-1.html">Link</a>).
					     <li> I was invited by Jiang Men to attend the <a target="_blank" href="https://mp.weixin.qq.com/s/333zqGhzrTXao-8Yc4TCJA">"将门ECCV 2020鲜声夺人云际会"</a> on 30/08/2020 as a panel guest of "奔涌吧后浪：从PhD到助理教授身份转变" session. <a target="_blank" href="https://mobile.techbeat.net/talks/MTU5ODkzODI4MzIxMi00MzAtNzA3NDE=?utm_campaign=eccv%E6%B4%BB%E5%8A%A8%E5%9B%9E%E9%A1%BE&utm_medium=%E7%BE%A4%E5%85%AC%E5%91%8A&utm_source=%E5%BE%AE%E4%BF%A1%E6%8A%80%E6%9C%AF%E7%A4%BE%E7%BE%A4&gio_link_id=L9G3eaB9">Video</a>, <a target="_blank" href="https://mp.weixin.qq.com/s/JnR_NIEubxCsZMl9cU3x_g">Review</a>
					     <li> I was invited by Prof. <a target="_blank" href="https://www.xjtlu.edu.cn/en/departments/academic-departments/electrical-and-electronic-engineering/staff/jimin-xiao">Jimin Xiao</a> at Xi'an Jiaotong-Liverpool University, Xi'an, China to deliver a talk on "Deep Learning for Human-Centric Image Analysis: From Face Recognition to Human Parsing" on 31/07/2020.
					     <li> I have co-organized a VALSE Webinar with Prof. <a target="_blank" href="http://people.ucas.edu.cn/~0003913?language=en">Shiguang Shan</a> on the topic of "Face-based Human Understanding: beyond Face Recognition" on 25/03/2020 (<a target="_blank" href="https://mp.weixin.qq.com/s/pvh4qISb1lwu31mK6G70Ig">Link1</a>, <a target="_blank" href="https://i.eqxiu.com/s/K364TUy8?share_level=4&from_user=9092cbce-bf77-4f72-8d6c-79ea640ddd2a&from_id=e2f4c5ee-f&share_time=1584662404673&from=timeline&isappinstalled=0">Link2</a>).
					     <li> I was invited by Prof. Congyan Lang at Beijing Jiaotong University, Beijing, China to deliver a talk on "Deep Learning for Human-Centric Image Analysis: From Face Recognition to Human Parsing" on 24/10/2019.
					     <li> I was <a href="pub/BAIDU.pdf" target="_blank">invited</a> by Dr. Jingtuo Liu at Baidu, Beijing, China to deliver a talk on "Deep Learning for Human-Centric Image Analysis: From Face Recognition to Human Parsing" on 05/09/2019.
					     <li> I was <a href="pub/HERAN_invitation.jpg" target="_blank">invited</a> by Prof. <a target="_blank" href="http://www.nlpr.ia.ac.cn/english/irds/People/rhe.html">Ran He</a> at Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China to deliver a talk on "Deep Learning for Human-Centric Image Analysis: From Face Recognition to Human Parsing" on 29/08/2019.
					     <li> I was invited by Huawei Noah's Ark Lab to deliver a talk on "Understanding Humans in Visual Scenes" on 13th June 2019.
					     <li> I was <a href="pub/jianzhao-PCL.pdf" target="_blank">invited</a> by Peng Cheng Laboratory (<a target="_blank" href="http://www.pcl.ac.cn/">PCL</a>) to attend the 2019 Overseas Young Scientist Forum at Shenzhen China during 30/03/2019-01/04/2019 and deliver a talk on "Deep Learning for Human-Centric Image Analysis: From Face Recognition to Human Parsing".
					     <li> I delivered a <a target="_blank" href="http://valser.org/2019/#/poster">spotlight</a> talk on "Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing" on VALSE 2019.      
					     <li> I was invited by CoLab, School of Computer, Beihang University to deliver a talk on "Deep Learning for Human-Centric Image Analysis: From Face Recognition to Human Parsing" on 23rd March 2019.
					     <li> I was invited by Tencent Deep Sea AI Lab to deliver a talk "Margin-based Representation Learning, Residual Knowledge Distillation and Prior-Aided Super Resolution" on 01st March 2019.
					     <li> I was invited by UBTECH to deliver a talk "Deep Learning for Human-Centric Image Understanding" on 08th January 2019.
					     <li> I was invited by OmniVision to deliver a talk "Facial Analytics" on 16th November 2018.
					     <li> I was invited by Jiang Men to deliver a talk "Deep Learning for Human-Centric Image Understanding" on 30th August 2018 (<a target="_blank" href="https://mp.weixin.qq.com/s/nZcGJZwXmJvvB72EnBtsCA">Link</a>, <a target="_blank" href="pub/JiangMen_Poster.jpeg">Poster</a>, <a target="_blank" href="https://mp.weixin.qq.com/s/BZsopAYrUadQRdwj-JwZKA">Summary</a>).
					     <li> I was invited by VALSE Webinar to deliver a talk "Deep Learning for Human-Centric Image Understanding" on 22nd August 2018 (<a target="_blank" href="https://mp.weixin.qq.com/s/ZKjR-l3pz06TbL5URHJGWw">Link</a>, <a target="_blank" href="https://mp.weixin.qq.com/s/jEFv4mfimKZW5EIahPATIg">Summary</a>).	
					     <li> I represented our group to "Launch of NUS new Vision, Mission and Values" at University Culture Center on 15th August 2018, and presented our recent work on Facial Analytics to NUS President Prof. <a href="http://president.nus.edu.sg/biography.php" target="_blank">Tan Eng Chye</a>. <a href="https://www.instagram.com/p/BmhlvOvg3be/?utm_source=ig_share_sheet&igshid=56r2rgyrhc5v" target="_blank">NUS Instagram</a>, <a href="pub/Instagram.jpeg" target="_blank">NUS News</a>, <a href="pub/20180815.jpeg" target="_blank">Gallery</a>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
			    
                        <div class="section color-2">
                            <div class="section-container">
                                <div class="row">
                                    <div id="awards" class="col-md-10 col-md-offset-1">
                                        <div class="title text-center">
                                            <h3>Selected Awards</h3>
                                        </div>
                                        <ul type=disc>
					     <li> 1st-Place Award, 9th author, <a target="_blank" href="https://ibug.doc.ic.ac.uk/resources/masked-face-recognition-challenge-workshop-iccv-21/">Masked Face Recognition Challenge</a> (WebFace260M Track) with ICCV 2021. <a href="pub/WebFace260M.jpg" target="_blank">Award Certificate</a>
					     <li> 2020-2022 Young Elite Scientist Sponsorship Program, China Association for Science and Technology. <a target="_blank" href="http://www.csig.org.cn/detail/3056">CSIG Official Announcement</a>, <a target="_blank" href="https://mp.weixin.qq.com/s/yGc_VTCNgqYRKAo75hre8g">CSIG Official News</a>, <a target="_blank" href="https://www.cast.org.cn/art/2021/9/9/art_458_168103.html">CAST Official Announcement</a>, <a href="pub/CAST.pdf" target="_blank">CAST Official Announcement Doc</a>, <a href="pub/Certificate-CAST.PDF" target="_blank">Certificate</a>
					     <li> <a href="pub/360-1.jpg" target="_blank">A-Level Certificate</a>, 4th author, <a target="_blank" href="https://ai.xm.gov.cn/">China Artificial Intelligence Competition</a> Activity Recognition Track, 2020. <a href="pub/360.jpg" target="_blank">Award Ceremony</a>
					     <li> 2021-2023 Beijing Young Elite Scientist Sponsorship Program, Beijing Association for Science and Technology. <a target="_blank" href="http://www.bsig.org.cn/detail/2430">BSIG Official Announcement</a>
					     <li> 2021-2023 Youth Program of National Natural Science Foundation of China, National Natural Science Foundation of China. <a href="pub/NSFC2020.pdf" target="_blank">Approval Notification</a>
					     <li> Lee Hwee Kuan Award (Gold Award), 1st author, PREMIA 2019. <a href="pub/PREMIA-19.jpeg" target="_blank">Award Certificate</a>, <a target="_blank" href="http://www.premiasg.org/for-members/premia-best-student-paper-awards/premia-best-student-paper-awards-2019/">PREMIA Official Announcement</a>
					     <li> Best Student Paper Award, 1st author, ACM MM 2018. <a href="pub/ACM MM18_Best Student Paper.pdf" target="_blank">Award Certificate</a>, <a target="_blank" href="http://www.acmmm.org/2018/awards/">ACM Official News</a>, <a target="_blank" href="https://www.eng.nus.edu.sg/2018/lv-team-wins-the-best-student-paper-award-at-acm-mm-2018/">NUS FOE News</a>, <a target="_blank" href="http://ece.nus.edu.sg/drupal/?q=node/25">NUS ECE Announcement</a>, <a target="_blank" href="http://ece.nus.edu.sg/drupal/node/243">NUS ECE News</a>
					     <li> 1st-Place Award, 1st author, MS-Celeb-1M face recognition <a target="_blank" href="http://www.msceleb.org/leaderboard/iccvworkshop-c1">hard set</a>/<a target="_blank" href="http://www.msceleb.org/leaderboard/iccvworkshop-c1">random set</a>/<a target="_blank" href="http://www.msceleb.org/leaderboard/c2">low-shot learning</a> challenges with ICCV 2017. <a href="http://mp.weixin.qq.com/s/-G94Mj-8972i2HtEcIZDpA" target="_blank">WeChat News</a>, <a target="_blank" href="http://ece.nus.edu.sg/drupal/?q=node/215">NUS ECE News</a>, <a href="pub/ECE_Poster.jpeg" target="_blank">NUS ECE Poster</a>, <a href="pub/MS-Track1.jpeg" target="_blank">Award Certificate for Track-1</a>, <a href="pub/MS-Track2.jpeg" target="_blank">Award Certificate for Track-2</a>, <a href="pub/MS-Awards.jpeg" target="_blank">Award Ceremony</a>
					     <li> 2nd-Place Award, 1st author, L.I.P human <a target="_blank" href="http://hcp.sysu.edu.cn/lip/leaderboard.php">parsing/pose</a> estimation challenges with CVPR 2017. <a href="pub/LIP_Certificate_Parsing.pdf" target="_blank">Award Certificate for Parsing</a>, <a href="pub/LIP_Certificate_Pose.pdf" target="_blank">Award Certificate for Pose</a>, <a href="pub/LIP-Awards.jpeg" target="_blank">Award Ceremony</a>
					     <li> 1st-Place Award, 1st author, NIST IJB-A unconstrained face <a href="pub/IJBA_11_report.pdf" target="_blank">verification</a>/<a href="pub/IJBA_1N_report.pdf" target="_blank">identification</a> challenges, 2017. <a href="https://mp.weixin.qq.com/s/s9H_OXX-CCakrTAQUFDm8g" target="_blank">WeChat News</a>
					     <li> 3rd-Place Award, 2nd author, MS-Celeb-1M face recognition <a target="_blank" href="https://www.microsoft.com/en-us/research/project/ms-celeb-1m-challenge-recognizing-one-million-celebrities-real-world/">hard set</a> challenge with ACM MM 2016.
                                             <li> Excellent Student Award (<10%), School of Computer, National University of Defense Technology, 2016.
                                             <li> Excellent Student Award (<10%), School of Computer, National University of Defense Technology, 2015.
　　                                          <li> Excellent Graduate Award (<2%), National University of Defense Technology, 2014.
                                             <li> Excellent Student Award (<2%), National University of Defense Technology, 2014. <a href="pub/14ExcellentStudentAward.jpeg" target="_blank">Award Certificate</a>
                                             <li> Guanghua Fellowship (<2%), National University of Defense Technology, 2014. <a href="pub/Guanghua.jpeg" target="_blank">Award Certificate</a>
                                             <li> Contribution Prize, for Engineering Implementation of Tianhe-2 supercomputer (No.1 on Top500, Jun, 2013), National University of Defense Technology, 2013. <a href="pub/13Tianhe.jpeg" target="_blank">Award Certificate</a>
					     <li> 3rd-Place Award, 1st author, 13th "Great Wall Information Cup" challenge, National University of Defense Technology, 2013.
                                             <li> Excellent Student Award (<10%), School of Computer, National University of Defense Technology, 2013. <a href="pub/13ExcellentStudentAward.jpeg" target="_blank">Award Certificate</a>
                                             <li> 1st-Place Award, 1st author, Big Data Processing and Information Sub-Forum of the 6th Graduate Innovation Forum, Provincial Education Department of Hunan Province, 2013. <a href="pub/13FirstPrize.jpeg" target="_blank">Award Certificate</a>
                                             <li> Excellent Graduate Award (<2%), Beihang University, 2012. <a href="pub/12ExcellentGraduate.jpeg" target="_blank">Award Certificate</a>
                                             <li> 2nd-Place Award, 1st author, 5th Student Research Training Program (SRTP), Beihang University, 2012. <a href="pub/SRTP.jpeg" target="_blank">Award Certificate</a>
                                             <li> National Endeavor Fellowship, Central Government & Beijing Government of China, 2011.
                                             <li> 3rd-Place Award, 1st author, "Feng Ru Cup" challenge, School of Automation Science and Electrical Engineering, Beihang University, 2011. <a href="pub/11Fengru.jpeg" target="_blank">Award Certificate</a>
                                             <li> SMC Fellowship, Beihang University, 2010.
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                            
                        <div class="pagecontents">
                            <div class="section color-1">
                                <div class="section-container">
                                    <div id="contact" class="row">
                                        <div  class="col-md-10 col-md-offset-1">
                                            <div class="title text-center">
                                                <h3>Contact</h3> 
                                            </div>
                                            <p><b>Email</b>: ruochen.wu@upc.edu OR plawuruochen001@gmail.com</p>
                                            <p><b>Phone/WhatsApp</b>: +34 685 660 833</p>
					    <p><b>WeChat</b>: 前哨 <a href="pub/wechat.jpg" target="_blank"><i class="fab fa-weixin"></i></a></p>
                                            <p><b>Address</b>: D3-Campus Nord-UPC, Despatx 114, C. Jordi Girona 1-3, 08034 Barcelona, Spain</p>
<p style="margin-top:25px;font-size:smaller;text-align:center">Modified: 20 October 2022</p>                          
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5o66f75yvk2&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33&amp;s=170" async="async"></script>
 </div>
                                    </div>
                                </div>

                            </div>
                    </div>
                </div>
        </div>
</div>        </div>

<script>
  mixpanel.track("Page Rc-W024.github.io load");
</script>
</body>
</html>
